{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c60ce679-8976-457a-ad1d-678668782a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import shutil\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "import strax\n",
    "from bson import json_util\n",
    "from tqdm import tqdm\n",
    "import lz4.frame as lz4\n",
    "\n",
    "import helix as hx\n",
    "from helix import units\n",
    "import numpy as np\n",
    "import strax as sx                    \n",
    "import numba\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import sys\n",
    "import os\n",
    "import shutil\n",
    "from glob import glob\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "run_id = 'run10' \n",
    "duration = 10  # seconds\n",
    "raw_data_dir = 'toy_data'  # to save the raw toy data\n",
    "helix_data_dir = 'test_helix_data'  # to save the run metadata\n",
    "baseline_step = 0  # add a baseline equal to baseline_step*channel_index to each channel\n",
    "# methods and classes marked with the @export decorator are added to the __all__ namespace to make them importable via\n",
    "# the star-notation ('from .module_name import *')\n",
    "export, __all__ = strax.exporter()\n",
    "\n",
    "\n",
    "@export\n",
    "def get_pink_psd(trace_length, sampling_dt, noise_std):\n",
    "    \"\"\"\n",
    "    Returns folded PSD corresponding to 1/f pink noise, empirically scaled to make the standard deviation of the noise\n",
    "    produced from this PSD to be close to the provided noise_std value\n",
    "\n",
    "    :param trace_length: length of noise traces in samples\n",
    "    :param sampling_dt: sampling time in ns\n",
    "    :param noise_std: noise standard deviation\n",
    "    :return: a tuple of (f, psd), where f is the array of frequencies in Hz, and psd is the array of PSD components\n",
    "    in A^2/Hz. Can be plotted with plt.loglog(f, psd)\n",
    "    \"\"\"\n",
    "    f = scipy.fft.rfftfreq(trace_length, d=sampling_dt / units.s)\n",
    "    f[0] = f[1]\n",
    "    # empirical approximate scaling to match the standard deviation of the resulting noise.\n",
    "    # This is totally crazy, it's a random expression that scales the PSD in a way that the standard deviation of the\n",
    "    # noise produced from this PSD somewhat matches the requested noise_std\n",
    "    # TODO: derive the actual scaling that would properly work and make sense instead of this monster\n",
    "    scaling = 1 / (1 + (np.log10(trace_length) - 4.5) / 10) ** 2 / 10.3\n",
    "    psd = scaling*(noise_std**2) / f\n",
    "    psd[-1] = psd[-1] / 2\n",
    "    # Could use 0 for the DC component of the PSD, but it messes up the plotting in log scale.\n",
    "    # The value doesn't matter anyway, we are not generating noise DC components. Using the smallest positive float\n",
    "    psd[0] = np.nextafter(1, 2)\n",
    "    f[0] = 0\n",
    "    return f, psd\n",
    "\n",
    "def generate_silent_traces(n_traces, psd, sampling_frequency=1.0):\n",
    "    \"\"\"\n",
    "    Function to generate silent traces (zeros) with the same structure as the noise generator.\n",
    "    :param n_traces: int. Number of traces to generate.\n",
    "    :param psd: ndarray. Folded power spectral density (not used, but kept for structure consistency).\n",
    "    :param sampling_frequency: float. Sample frequency in Hz.\n",
    "    :returns: ndarray. An array of silent (zero) traces.\n",
    "    \"\"\"\n",
    "    trace_length = hx.psd_to_trace_length(len(psd))\n",
    "    \n",
    "    # Generate an array of zeros with the appropriate shape\n",
    "    silent_traces = np.zeros((n_traces, trace_length))\n",
    "    \n",
    "    return silent_traces\n",
    "@export\n",
    "def load_traces_from_csv(file_path):\n",
    "    \"\"\"\n",
    "    Reads the CSV file containing traces and returns them as a NumPy array.\n",
    "    :param file_path: str. Path to the CSV file.\n",
    "    :returns: ndarray. Array of traces with shape (n_traces, 32768).\n",
    "    \"\"\"\n",
    "    traces_df = pd.read_csv(file_path, header=None)\n",
    "    traces_array = traces_df.to_numpy(dtype=np.float32)\n",
    "    return traces_array\n",
    "    \n",
    "def generate_toy_data(run, duration, directory='toy_data', record_length=hx.DEFAULT_RECORD_LENGTH,\n",
    "                      sampling_dt=hx.DEFAULT_SAMPLING_DT, template_length=hx.DEFAULT_TEMPLATE_LENGTH,\n",
    "                      channel_map=hx.DEFAULT_CHANNEL_MAP, noise_std=0, event_rate=1, overwrite=False, helix_data_dir='test_helix_data', baseline_step=0, traces_file='traces.csv'):\n",
    "    \"\"\"\n",
    "    Generates and saves toy data with multiple channels of vacuum and submerged types, physics events consisting of UV\n",
    "    and QP signals, as well as background lone hits and muon saturated events. CAUTION: it's slow!\n",
    "    Noise is uncorrelated pink noise, with a correlated 5 kHz feature in all channels. Channels have different baselines\n",
    "\n",
    "    :param run: run id\n",
    "    :param duration: run duration in seconds. Caution: the function is slow, don't ask to generate days of data\n",
    "    :param directory: output directory, where a directory with run_id name will be created\n",
    "    :param record_length: length of records in each file in time samples\n",
    "    :param sampling_dt: sampling time in ns\n",
    "    :param template_length: length of UV and QP templates\n",
    "    :param channel_map: dictionary of channel types and channel number ranges\n",
    "    :param noise_std: standard deviation of the noise\n",
    "    :param event_rate: rate of physics events in Hz\n",
    "    :param lone_hit_rate: rate of lone background hits in Hz (events with a UV signal in only one channel)\n",
    "    :param muon_rate: rate of muon events\n",
    "    :param overwrite: a boolean specifying whether the function should overwrite data, if it already exists. If False,\n",
    "    a RuntimeError is raise when a directory with the same run id exists\n",
    "    :param helix_data_dir: a directory to save the run metadata. Should be the same as the helix output directory.\n",
    "    :param baseline_step: add a baseline to each channel, equal to baseline_step * channel_index\n",
    "    \"\"\"\n",
    "\n",
    "    traces_array = load_traces_from_csv(traces_file)\n",
    "    run_dir = os.path.join(directory, run)\n",
    "    if os.path.exists(run_dir):\n",
    "        if overwrite:\n",
    "            shutil.rmtree(run_dir)\n",
    "        else:\n",
    "            raise RuntimeError(f'Directory {run_dir} already exists.')\n",
    "\n",
    "    os.makedirs(run_dir)\n",
    "\n",
    "    record_length_s = record_length * sampling_dt / units.s\n",
    "    n_records = int(duration / record_length_s)\n",
    "    channels = hx.Channels(channel_map)\n",
    "    n_channels = len(channels)\n",
    "    batch_size = 1  # number of records per batch\n",
    "    sampling_frequency = 1 / (sampling_dt / units.s)\n",
    "\n",
    "    _, psd = get_pink_psd(record_length * batch_size, sampling_dt, noise_std)\n",
    "\n",
    "\n",
    "    # adding different baselines to each channel\n",
    "    baseline = baseline_step * np.arange(n_channels)    \n",
    "\n",
    "\n",
    "    n_batches = 1\n",
    "    # # of baches, if set >1 will have repeat\n",
    "    #print(f\"    n_batches:            {n_batches}\")\n",
    "\n",
    "    batch_length_s = 100\n",
    "    # \n",
    "    #print(f\"    batch_length_s:            {batch_length_s}\")\n",
    "\n",
    "    n_events = np.full(n_batches, int(round(event_rate * batch_length_s)), dtype=int)\n",
    "    print(f\"    n_events:            {n_events}\")\n",
    "\n",
    "\n",
    "    for i in tqdm(range(n_batches)):\n",
    "        #waveform should be generated under each event and has the dimension of (50, 1250000)\n",
    "        waveform = generate_silent_traces(n_channels, psd, sampling_frequency)\n",
    "\n",
    "        # generate random event times\n",
    "        event_times = np.random.randint(0, batch_size * record_length - template_length,\n",
    "                                        size=n_events[i])\n",
    "\n",
    "        # adding physics events and muons to the traces\n",
    "        for ich, ch_type in enumerate(channels.types):\n",
    "            for j in range(n_events[i]):\n",
    "                if ich == 0:\n",
    "                    trace_idx = j % traces_array.shape[0]  # Assign one real trace per event\n",
    "                    print(f\"    trace_idx:            {trace_idx}\")\n",
    "                    selected_trace = traces_array[trace_idx]\n",
    "                    start_idx = event_times[j] \n",
    "                    print(f\"    start_idx:            {start_idx}\")\n",
    "                    end_idx = min(start_idx + hx.DEFAULT_TEMPLATE_LENGTH, waveform.shape[1])\n",
    "                    waveform[ich, event_times[j]:event_times[j] + hx.DEFAULT_TEMPLATE_LENGTH] +=\\\n",
    "                        selected_trace[:]\n",
    "\n",
    "        # splitting the data into record_length records\n",
    "        for j in range(batch_size):\n",
    "            i_record = i * batch_size + j\n",
    "            if i_record == n_records:\n",
    "                break\n",
    "            fn = f'{directory}/{run}/{run}-{i_record:05d}'\n",
    "            # saving the data as a flattened array\n",
    "            with open(fn, mode='wb') as f:\n",
    "                data = np.ascontiguousarray(waveform[:, j * record_length:(j + 1) * record_length], dtype=np.int16)\n",
    "                f.write(lz4.compress(data))\n",
    "\n",
    "    # saving run metadata\n",
    "    if not os.path.exists(helix_data_dir):\n",
    "        os.makedirs(helix_data_dir)\n",
    "\n",
    "    metadata_path = os.path.join(helix_data_dir, \"%s-metadata.json\" % run)\n",
    "    start = datetime.now().replace(microsecond=0)\n",
    "    end = start + timedelta(seconds=duration)\n",
    "    metadata = {'start': start, 'end': end}\n",
    "    with open(metadata_path, 'w') as f:\n",
    "        json.dump(metadata, f, default=json_util.default)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1afac77c-3f03-4c30-96f0-221d95aad364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    n_batches:            1\n",
      "    batch_length_s:            100\n",
      "    n_events:            [100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 1/1 [00:00<00:00, 12.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    trace_idx:            0\n",
      "    start_idx:            1089019\n",
      "    trace_idx:            1\n",
      "    start_idx:            1181111\n",
      "    trace_idx:            2\n",
      "    start_idx:            811955\n",
      "    trace_idx:            3\n",
      "    start_idx:            198130\n",
      "    trace_idx:            4\n",
      "    start_idx:            1182613\n",
      "    trace_idx:            5\n",
      "    start_idx:            183995\n",
      "    trace_idx:            6\n",
      "    start_idx:            967945\n",
      "    trace_idx:            7\n",
      "    start_idx:            1106965\n",
      "    trace_idx:            8\n",
      "    start_idx:            62597\n",
      "    trace_idx:            9\n",
      "    start_idx:            1110120\n",
      "    trace_idx:            10\n",
      "    start_idx:            871270\n",
      "    trace_idx:            11\n",
      "    start_idx:            1051858\n",
      "    trace_idx:            12\n",
      "    start_idx:            12741\n",
      "    trace_idx:            13\n",
      "    start_idx:            797392\n",
      "    trace_idx:            14\n",
      "    start_idx:            73004\n",
      "    trace_idx:            15\n",
      "    start_idx:            878507\n",
      "    trace_idx:            16\n",
      "    start_idx:            757967\n",
      "    trace_idx:            17\n",
      "    start_idx:            297749\n",
      "    trace_idx:            18\n",
      "    start_idx:            1204220\n",
      "    trace_idx:            19\n",
      "    start_idx:            867203\n",
      "    trace_idx:            20\n",
      "    start_idx:            1188935\n",
      "    trace_idx:            21\n",
      "    start_idx:            208107\n",
      "    trace_idx:            22\n",
      "    start_idx:            731757\n",
      "    trace_idx:            23\n",
      "    start_idx:            1191355\n",
      "    trace_idx:            24\n",
      "    start_idx:            843034\n",
      "    trace_idx:            25\n",
      "    start_idx:            1057401\n",
      "    trace_idx:            26\n",
      "    start_idx:            631470\n",
      "    trace_idx:            27\n",
      "    start_idx:            824493\n",
      "    trace_idx:            28\n",
      "    start_idx:            670030\n",
      "    trace_idx:            29\n",
      "    start_idx:            473427\n",
      "    trace_idx:            30\n",
      "    start_idx:            202468\n",
      "    trace_idx:            31\n",
      "    start_idx:            159555\n",
      "    trace_idx:            32\n",
      "    start_idx:            247506\n",
      "    trace_idx:            33\n",
      "    start_idx:            89188\n",
      "    trace_idx:            34\n",
      "    start_idx:            790091\n",
      "    trace_idx:            35\n",
      "    start_idx:            270601\n",
      "    trace_idx:            36\n",
      "    start_idx:            490750\n",
      "    trace_idx:            37\n",
      "    start_idx:            61105\n",
      "    trace_idx:            38\n",
      "    start_idx:            1014419\n",
      "    trace_idx:            39\n",
      "    start_idx:            1061878\n",
      "    trace_idx:            40\n",
      "    start_idx:            527902\n",
      "    trace_idx:            41\n",
      "    start_idx:            1100195\n",
      "    trace_idx:            42\n",
      "    start_idx:            307102\n",
      "    trace_idx:            43\n",
      "    start_idx:            132963\n",
      "    trace_idx:            44\n",
      "    start_idx:            1153812\n",
      "    trace_idx:            45\n",
      "    start_idx:            1137813\n",
      "    trace_idx:            46\n",
      "    start_idx:            1029324\n",
      "    trace_idx:            47\n",
      "    start_idx:            345031\n",
      "    trace_idx:            48\n",
      "    start_idx:            15881\n",
      "    trace_idx:            49\n",
      "    start_idx:            866061\n",
      "    trace_idx:            50\n",
      "    start_idx:            1195452\n",
      "    trace_idx:            51\n",
      "    start_idx:            1110860\n",
      "    trace_idx:            52\n",
      "    start_idx:            520122\n",
      "    trace_idx:            53\n",
      "    start_idx:            737333\n",
      "    trace_idx:            54\n",
      "    start_idx:            226347\n",
      "    trace_idx:            55\n",
      "    start_idx:            222669\n",
      "    trace_idx:            56\n",
      "    start_idx:            680676\n",
      "    trace_idx:            57\n",
      "    start_idx:            934789\n",
      "    trace_idx:            58\n",
      "    start_idx:            1145720\n",
      "    trace_idx:            59\n",
      "    start_idx:            970663\n",
      "    trace_idx:            60\n",
      "    start_idx:            795006\n",
      "    trace_idx:            61\n",
      "    start_idx:            1078929\n",
      "    trace_idx:            62\n",
      "    start_idx:            658188\n",
      "    trace_idx:            63\n",
      "    start_idx:            550457\n",
      "    trace_idx:            64\n",
      "    start_idx:            1119980\n",
      "    trace_idx:            65\n",
      "    start_idx:            129897\n",
      "    trace_idx:            66\n",
      "    start_idx:            303155\n",
      "    trace_idx:            67\n",
      "    start_idx:            22200\n",
      "    trace_idx:            68\n",
      "    start_idx:            53445\n",
      "    trace_idx:            69\n",
      "    start_idx:            589694\n",
      "    trace_idx:            70\n",
      "    start_idx:            1023646\n",
      "    trace_idx:            71\n",
      "    start_idx:            64166\n",
      "    trace_idx:            72\n",
      "    start_idx:            241722\n",
      "    trace_idx:            73\n",
      "    start_idx:            521733\n",
      "    trace_idx:            74\n",
      "    start_idx:            1207082\n",
      "    trace_idx:            75\n",
      "    start_idx:            930815\n",
      "    trace_idx:            76\n",
      "    start_idx:            221282\n",
      "    trace_idx:            77\n",
      "    start_idx:            113651\n",
      "    trace_idx:            78\n",
      "    start_idx:            873441\n",
      "    trace_idx:            79\n",
      "    start_idx:            600837\n",
      "    trace_idx:            80\n",
      "    start_idx:            503228\n",
      "    trace_idx:            81\n",
      "    start_idx:            588817\n",
      "    trace_idx:            82\n",
      "    start_idx:            965870\n",
      "    trace_idx:            83\n",
      "    start_idx:            666974\n",
      "    trace_idx:            84\n",
      "    start_idx:            370661\n",
      "    trace_idx:            85\n",
      "    start_idx:            848184\n",
      "    trace_idx:            86\n",
      "    start_idx:            681402\n",
      "    trace_idx:            87\n",
      "    start_idx:            614470\n",
      "    trace_idx:            88\n",
      "    start_idx:            557516\n",
      "    trace_idx:            89\n",
      "    start_idx:            338404\n",
      "    trace_idx:            90\n",
      "    start_idx:            1169491\n",
      "    trace_idx:            91\n",
      "    start_idx:            358660\n",
      "    trace_idx:            92\n",
      "    start_idx:            1013080\n",
      "    trace_idx:            93\n",
      "    start_idx:            436241\n",
      "    trace_idx:            94\n",
      "    start_idx:            339713\n",
      "    trace_idx:            95\n",
      "    start_idx:            158853\n",
      "    trace_idx:            96\n",
      "    start_idx:            733389\n",
      "    trace_idx:            97\n",
      "    start_idx:            86581\n",
      "    trace_idx:            98\n",
      "    start_idx:            318300\n",
      "    trace_idx:            99\n",
      "    start_idx:            872450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# remove helix data corresponding to this run_id, if it exists\n",
    "for path in glob(f'{helix_data_dir}/*'):\n",
    "    if os.path.isdir(path):\n",
    "        shutil.rmtree(path)\n",
    "    else:\n",
    "        os.remove(path)\n",
    "    \n",
    "generate_toy_data(run_id, duration, raw_data_dir, helix_data_dir=helix_data_dir, overwrite=True, baseline_step=baseline_step)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6a75b2-5d93-4395-a110-32491beba97b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing old incomplete data in test_helix_data/run10-raw_records-igg4zuk5jh_temp\n",
      "Removing old incomplete data in test_helix_data/run10-qp_triggers-i3vt2yhwmr_temp\n",
      "Removing old incomplete data in test_helix_data/run10-uv_triggers-xdpckrv34a_temp\n",
      "Removing old incomplete data in test_helix_data/run10-events-5zxopmcya6_temp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading events: |                                             | 0.00 % [00:00<?]"
     ]
    }
   ],
   "source": [
    "context = sx.Context(storage=[sx.DataDirectory(helix_data_dir, provide_run_metadata=True), ],\n",
    "                     register=[hx.MMCRecords,\n",
    "                               hx.QPTriggers, hx.UVTriggers,\n",
    "                               hx.Events, hx.NoiseEvents,\n",
    "                               hx.NoisePSDs, hx.FitResults])    # all the plugins required for getting fit_results\n",
    "\n",
    "# creating a dictionary of plugins' options that we want to modify. \n",
    "config = {'run_metadata_directory': helix_data_dir,      # for the hx.ToyDataRawRecords plugin\n",
    "          'noise_events_random_seed': 0}  # for the hx.NoiseEvents plugin\n",
    "\n",
    "context.set_config(config)\n",
    "events = context.get_array(run_id, 'events')\n",
    "\n",
    "raw_data = events['channel_data']\n",
    "raw_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78238468-300f-4cf2-8e94-ef448588df76",
   "metadata": {},
   "source": [
    "Loading events: |                  | 0.00 % [00:03<?], #78 (0.02 s). 4528.3 MB/s  \n",
    "(964, 50, 33168)  \n",
    "Loading fit_results: |                | 0.00 % [03:26<?], #78 (1.16 s). 9.8 kB/s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfa46ad-4df0-4a92-849c-571cc3aaf2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_results = context.get_array(run_id, 'fit_results')  # hx.FitResults plugin provides this data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08969785-aeeb-41de-8cd9-5c04bfdad22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the channel map and loading the templates\n",
    "channels = hx.Channels(hx.DEFAULT_CHANNEL_MAP)\n",
    "\n",
    "template_path = './plugins/event_rqs/default_templates.npy'\n",
    "templates = np.load(template_path, allow_pickle=True)\n",
    "uv_template = templates[0]\n",
    "qp_template = templates[1]\n",
    "\n",
    "\n",
    "# change this to choose another event if the one below is a bad one by chance\n",
    "i = 25\n",
    "\n",
    "plt.figure(figsize=(28,16))\n",
    "artificial_baselines = np.arange(len(channels)) * 300  # adding artificial baselines to each channel to separate the channels on the plot\n",
    "plt.plot(events['channel_data'][i].T + artificial_baselines, lw=0.5, alpha=0.8, color='C0')  # plotting data in each channel\n",
    "\n",
    "event = fit_results[i]\n",
    "\n",
    "# plotting two-template fits in the vacuum channels\n",
    "for i_vac, i_ch in enumerate(channels.indices_of_type(hx.ChannelType.VACUUM)):\n",
    "    # i_vac is the ordinal index of the vacuum channel\n",
    "    # i_ch is the corrending ordinal index in the array of all channels\n",
    "    fit = event['vacuum_channel_uv_amplitude'][i_vac] * np.roll(uv_template, event['vacuum_channel_uv_offset'][i_vac]) \n",
    "    x = np.arange(len(uv_template)) - hx.DEFAULT_ALLOWED_FIT_SHIFTS[0]  # currently, the FitResults plugin does not fit the entire event. It skips -hx.DEFAULT_ALLOWED_FIT_SHIFTS[0] samples.\n",
    "    plt.plot(x, fit+artificial_baselines[i_ch], lw=1, alpha=0.8, color='C1')\n",
    "\n",
    "\n",
    "plt.xlabel('Time (samples)')\n",
    "plt.ylabel('Current (ADC units)')\n",
    "plt.title(f'Apply MMC readout on silent traces')\n",
    "#plt.savefig('raw_traces_on_silent_plot.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d291ead2-7ec8-4811-afe6-607c8a884357",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257c9b2b-a857-45a4-a0ba-14b107306074",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85e2913-867a-429c-a933-3d41d8c7f57d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68b2345-6212-4245-9e20-f6831b731141",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e728af-9de5-498a-9f90-f9d604d0f5a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc33254-aba3-4e46-b69a-11d22e578a90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb5e8f5-1259-4a9e-a246-b2e4710811ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d9a393-82ad-4343-abe8-608fffdfc394",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d903d2-0a20-4b4f-bb00-79c3fbdacb6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b700c5-b4e6-4f5e-8184-1aaf99780f15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fec65a6-fe5e-4afb-af9a-a4c6fcf8fc62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6d9d9c-9bc3-442c-8ebd-b1f77791b7da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672d1748-406f-400e-971b-1f6c13b1bf38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2453899d-6d8c-484a-8a42-d55d5d2d06c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3de12e-4fbb-4b69-adfa-3e147ab9c920",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c41001-6b42-4ffc-b618-fe5ad0a23691",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10216e30-91d1-4984-90cd-c0dcf7f06746",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1314bf9e-dcee-446c-9d53-263978486a57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203d5c5b-4337-4e8b-808a-26ae2576dbd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c10230-8eb6-422f-8cce-cd896c732764",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b76378-4310-484c-87be-97245516529a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62c82d90-6d3e-4405-baba-c53f8bb36e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helix import units\n",
    "import numpy as np\n",
    "import helix as hx\n",
    "def make_default_templates():\n",
    "    uv_template = hx.get_analytical_template(length=hx.DEFAULT_OF_LENGTH, sampling_dt=hx.DEFAULT_SAMPLING_DT)\n",
    "    qp_template = hx.get_analytical_template(2 * units.ms, length=hx.DEFAULT_OF_LENGTH,\n",
    "                                             sampling_dt=hx.DEFAULT_SAMPLING_DT)\n",
    "    templates = np.array([uv_template, qp_template])\n",
    "\n",
    "    np.save('plugins/event_rqs/default_templates.npy', templates)\n",
    "make_default_templates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1450588c-89fa-4ce2-9e7d-c46c77f83fd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2162ffae-da5d-42cd-b19f-81929e967bf1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314bd184-ffdd-48e5-9d6f-0836e2c90e66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148210b3-c89f-4c5a-8081-cab9979f8803",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02cb69f3-bc9d-482f-97a3-0708a027ce38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7d3b8b-ff9d-44cc-8115-9d7c036698ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa43bb2-a3f3-459d-8f12-7553857eb23e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ecdc9c-22ef-41f6-9cc1-93f4aa11c7f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0931493a-9cfa-49e0-b304-fa77e65bd211",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1500cc-4e9f-4818-93f7-8e6308253b9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
