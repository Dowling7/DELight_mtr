{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "453cff01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import signal\n",
    "import scipy.stats\n",
    "\n",
    "def get_gdf_kernel(sigma, n_sigma=3):\n",
    "    \"\"\"\n",
    "    Returns normalized Gaussian Derivative to be used as the GDF kernel.\n",
    "    :param sigma: width of the Gaussian in time samples\n",
    "    :param n_sigma: number of sigmas to include in the kernel\n",
    "    :return: GDF kernel as a np.array\n",
    "    \"\"\"\n",
    "    x = np.arange(-sigma * n_sigma, sigma * n_sigma + 1)\n",
    "    gaus = scipy.stats.norm(scale=sigma).pdf(x)\n",
    "    kernel = np.diff(gaus)\n",
    "    step_function = -np.heaviside(x[:-1], 1)\n",
    "    return kernel / np.dot(kernel, step_function)\n",
    "\n",
    "def threshold_trigger_1d(raw_record, kernel, trigger_threshold=100, deactivation_threshold_coefficient=1, trigger_holdoff=0):\n",
    "    \"\"\"\n",
    "    Fast threshold trigger with convolution for a single trace.\n",
    "    Assumes a simple threshold crossing (with optional holdoff).\n",
    "    \"\"\"\n",
    "    filtered = signal.convolve(raw_record, kernel, mode='valid')\n",
    "    deactivate_threshold = trigger_threshold * deactivation_threshold_coefficient\n",
    "\n",
    "    triggered = False\n",
    "    hits = []\n",
    "    i = 0\n",
    "    while i < len(filtered):\n",
    "        if not triggered and filtered[i] > trigger_threshold:\n",
    "            hits.append(i)\n",
    "            triggered = True\n",
    "            i += trigger_holdoff  # fast skip\n",
    "        elif triggered and filtered[i] < deactivate_threshold:\n",
    "            triggered = False\n",
    "        i += 1\n",
    "\n",
    "    return filtered, hits\n",
    "\n",
    "def threshold_trigger_2d(records, sigma, trigger_threshold=100, deactivation_threshold_coefficient=1, trigger_holdoff=0, n_sigma=3):\n",
    "    \"\"\"\n",
    "    Optimized batch threshold trigger for multiple records with configurable sigma.\n",
    "    Generates the GDF kernel internally using sigma.\n",
    "\n",
    "    :param records: 2D array of traces (n_records, n_samples)\n",
    "    :param sigma: Gaussian sigma used for GDF kernel\n",
    "    :param trigger_threshold: Threshold for triggering\n",
    "    :param deactivation_threshold_coefficient: Coefficient for deactivation threshold\n",
    "    :param trigger_holdoff: Number of samples to hold off after trigger\n",
    "    :param n_sigma: Number of sigmas to include in the kernel\n",
    "    :return: (filtered_records, all_hits, total_hits)\n",
    "    \"\"\"\n",
    "    kernel = get_gdf_kernel(sigma, n_sigma)\n",
    "    num_records = len(records)\n",
    "    filtered_records = np.empty(num_records, dtype=object)\n",
    "    all_hits = []\n",
    "\n",
    "    kernel_len = len(kernel)\n",
    "    conv_len = records.shape[1] - kernel_len + 1\n",
    "\n",
    "    for i in range(num_records):\n",
    "        raw = records[i]\n",
    "        filtered = signal.convolve(raw, kernel, mode='valid')\n",
    "        filtered_records[i] = filtered\n",
    "\n",
    "        deactivate_threshold = trigger_threshold * deactivation_threshold_coefficient\n",
    "        hits = []\n",
    "        triggered = False\n",
    "        j = 0\n",
    "        while j < conv_len:\n",
    "            if not triggered and filtered[j] > trigger_threshold:\n",
    "                hits.append(j)\n",
    "                triggered = True\n",
    "                j += trigger_holdoff\n",
    "            elif triggered and filtered[j] < deactivate_threshold:\n",
    "                triggered = False\n",
    "            j += 1\n",
    "\n",
    "        all_hits.append(hits)\n",
    "\n",
    "    total_hits = sum(len(h) for h in all_hits)\n",
    "    return filtered_records, all_hits, total_hits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbde8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ka_data_1 = np.load('Ka_traces_1.npz')['data']\n",
    "ka_data_2 = np.load('Ka_traces_2.npz')['data']\n",
    "kb_data = np.load('Kb_traces.npz')['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d2343f50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(499, 32768)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kb_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cda62cff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwong/anaconda3/lib/python3.12/site-packages/TraceSimulator/TraceSimulator.py:185: RuntimeWarning: overflow encountered in exp\n",
      "  self.template = np.concatenate([(np.exp((xs - self.trigger_time) / self.tau_rise))[xs <= self.trigger_time], (np.exp(-(xs - self.trigger_time) / self.tau_decay))[xs > self.trigger_time]])\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "from TraceSimulator import TraceSimulator\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def read_yaml_to_dict(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        config_dict = yaml.safe_load(file)\n",
    "    return config_dict\n",
    "\n",
    "config = read_yaml_to_dict('config.yaml')\n",
    "ts = TraceSimulator(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fff2ad0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc55de5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean over first 2048 samples of first 44 traces: 10.9230\n",
      "Std over first 2048 samples of first 44 traces: 36.0846\n"
     ]
    }
   ],
   "source": [
    "trace, (x, y, z) = ts.generate(5890, type_recoil='NR', no_noise=True) \n",
    "\n",
    "slice_idx = slice(0, 2048)\n",
    "\n",
    "# Select only the first 44 traces\n",
    "selected_traces = trace[:44, :]\n",
    "\n",
    "# Compute mean and std across the first 2048 samples per trace\n",
    "simu_mean = np.mean(np.mean(selected_traces[:, slice_idx], axis=1))\n",
    "simu_std = np.mean(np.std(selected_traces[:, slice_idx], axis=1))\n",
    "\n",
    "print(f\"Mean over first 2048 samples of first 44 traces: {simu_mean:.4f}\")\n",
    "print(f\"Std over first 2048 samples of first 44 traces: {simu_std:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
