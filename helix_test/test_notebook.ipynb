{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ee6df47-9310-492f-a495-3a86aace0be1",
   "metadata": {},
   "source": [
    "To install helix, run `pip install -e /path/to/helix/repo` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28873021-2848-4f21-9936-83b40dc18236",
   "metadata": {},
   "outputs": [],
   "source": [
    "import helix as hx\n",
    "import strax as sx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e686cdfb-1a01-4c16-9c3f-f34bcdec3edd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "strax version: 2.0.3\n",
      "NumPy version: 1.23.5\n",
      "Numba version: 0.60.0\n",
      "Pandas version: 1.5.3\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import strax\n",
    "import numba\n",
    "import pandas as pd\n",
    "print(\"strax version:\", strax.__version__)\n",
    "print(\"NumPy version:\", np.__version__)\n",
    "print(\"Numba version:\", numba.__version__)\n",
    "print(\"Pandas version:\", pd.__version__)\n",
    "#strax latest version: 2.0.3\n",
    "#Numpy latest version: 2.2.1\n",
    "#Numba latest version: 0.60.0\n",
    "#Pandas latest version: 2.2.3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2819f30b-3bbd-4fae-9697-23f515a08955",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from glob import glob\n",
    "from matplotlib import pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b2136d-e9c3-461b-b347-aa2b64009dbf",
   "metadata": {},
   "source": [
    "## Generate toy data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545246ac-cf44-4277-b95b-5a82fb8b35ac",
   "metadata": {},
   "source": [
    "Toy data generator is very slow, might take ~20 seconds per 10 seconds of toy data. Don't ask for a lot of toy data if you don't want to wait forever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3a8b2e7-588c-4d47-9845-9ae4fe660b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_id = 'run10' \n",
    "duration = 10  # seconds\n",
    "raw_data_dir = 'toy_data'  # to save the raw toy data\n",
    "helix_data_dir = 'test_helix_data'  # to save the run metadata\n",
    "baseline_step = 0  # add a baseline equal to baseline_step*channel_index to each channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0804a4a8-ae06-4529-9429-835d28cd7089",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:38<00:00, 38.79s/it]\n"
     ]
    }
   ],
   "source": [
    "# remove helix data corresponding to this run_id, if it exists\n",
    "for path in glob(f'{helix_data_dir}/*'):\n",
    "    if os.path.isdir(path):\n",
    "        shutil.rmtree(path)\n",
    "    else:\n",
    "        os.remove(path)\n",
    "    \n",
    "hx.generate_toy_data(run_id, duration, raw_data_dir, helix_data_dir=helix_data_dir, overwrite=True, baseline_step=baseline_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97957f76-e969-4659-89c4-f370ff1c7b7f",
   "metadata": {},
   "source": [
    "## Process the toy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a8aaf228-1751-470c-a219-eb4b9efc6d32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing old incomplete data in test_helix_data/run10-raw_records-p2akieui5i_temp\n",
      "Removing old incomplete data in test_helix_data/run10-qp_triggers-lndpgukla7_temp\n",
      "Removing old incomplete data in test_helix_data/run10-uv_triggers-il2q6cmf4u_temp\n",
      "Removing old incomplete data in test_helix_data/run10-noise_events-ewlivewzgk_temp\n",
      "Removing old incomplete data in test_helix_data/run10-noise_psds-3ucezkkcs5_temp\n",
      "Removing old incomplete data in test_helix_data/run10-events-fb2oh2w25z_temp\n",
      "Removing old incomplete data in test_helix_data/run10-fit_results-p5h5rxo3zh_temp\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'plugins/event_rqs/default_templates.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 21\u001b[0m\n\u001b[1;32m     13\u001b[0m context\u001b[38;5;241m.\u001b[39mset_config(config)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# running the processing (or retrieving the data, if it was processed earlier)\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \n\u001b[1;32m     17\u001b[0m \n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m#psds = context.get_array(run_id, 'noise_psds')  # Helix needs to prebuild PSDs before calculating fit_results\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m fit_results \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfit_results\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# hx.FitResults plugin provides this data type\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# fit_results is a structured numpy array of events containing fields described in the FitResults documentation\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# one can work with it as a dictionary on numpy arrays, or as a numpy array of dictionaries. Works both ways. E.g.\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# fit_results['sum_uv_amplitude'][:100]  # amplitudes of UV signals in the sum of all channels in the first 100 events\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# fit_results[:100]['sum_uv_amplitude']  # same\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/delight/lib/python3.11/site-packages/strax/context.py:1799\u001b[0m, in \u001b[0;36mContext.get_array\u001b[0;34m(self, run_id, targets, save, max_workers, **kwargs)\u001b[0m\n\u001b[1;32m   1795\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1796\u001b[0m     source \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_iter(\n\u001b[1;32m   1797\u001b[0m         run_ids[\u001b[38;5;241m0\u001b[39m], targets, save\u001b[38;5;241m=\u001b[39msave, max_workers\u001b[38;5;241m=\u001b[39mmax_workers, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m   1798\u001b[0m     )\n\u001b[0;32m-> 1799\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msource\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m   1801\u001b[0m results \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate(results)\n\u001b[1;32m   1802\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "File \u001b[0;32m~/anaconda3/envs/delight/lib/python3.11/site-packages/strax/context.py:1799\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1795\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1796\u001b[0m     source \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_iter(\n\u001b[1;32m   1797\u001b[0m         run_ids[\u001b[38;5;241m0\u001b[39m], targets, save\u001b[38;5;241m=\u001b[39msave, max_workers\u001b[38;5;241m=\u001b[39mmax_workers, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m   1798\u001b[0m     )\n\u001b[0;32m-> 1799\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msource\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m   1801\u001b[0m results \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate(results)\n\u001b[1;32m   1802\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "File \u001b[0;32m~/anaconda3/envs/delight/lib/python3.11/site-packages/strax/context.py:1584\u001b[0m, in \u001b[0;36mContext.get_iter\u001b[0;34m(self, run_id, targets, save, max_workers, time_range, seconds_range, time_within, time_selection, selection, keep_columns, drop_columns, allow_multiple, progress_bar, multi_run_progress_bar, chunk_number, processor, combining, **kwargs)\u001b[0m\n\u001b[1;32m   1576\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontext_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m7200\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   1577\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontext_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_lazy\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontext_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_multiprocess\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1578\u001b[0m     ):\n\u001b[1;32m   1579\u001b[0m         \u001b[38;5;66;03m# For allow_multiple we don't want allow this when in lazy mode\u001b[39;00m\n\u001b[1;32m   1580\u001b[0m         \u001b[38;5;66;03m# with long timeouts (lazy-mode is disabled if multiprocessing\u001b[39;00m\n\u001b[1;32m   1581\u001b[0m         \u001b[38;5;66;03m# so if that is activated, we can also continue)\u001b[39;00m\n\u001b[1;32m   1582\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot allow_multiple in lazy mode or with long timeouts.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1584\u001b[0m components \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_components\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1585\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1586\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtargets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1587\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1588\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtime_range\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtime_range\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1589\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunk_number\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunk_number\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1590\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmulti_run_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmulti_run_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1591\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcombining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcombining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1592\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1594\u001b[0m \u001b[38;5;66;03m# Cleanup the temp plugins\u001b[39;00m\n\u001b[1;32m   1595\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_plugin_class_registry\u001b[38;5;241m.\u001b[39mkeys()):\n",
      "File \u001b[0;32m~/anaconda3/envs/delight/lib/python3.11/site-packages/strax/context.py:1332\u001b[0m, in \u001b[0;36mContext.get_components\u001b[0;34m(self, run_id, targets, save, time_range, chunk_number, multi_run_progress_bar, combining)\u001b[0m\n\u001b[1;32m   1330\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m plugins\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[1;32m   1331\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_plugin_config(d, run_id, tolerant\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m-> 1332\u001b[0m     \u001b[43md\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetup\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m strax\u001b[38;5;241m.\u001b[39mProcessorComponents(\n\u001b[1;32m   1334\u001b[0m     plugins\u001b[38;5;241m=\u001b[39mplugins,\n\u001b[1;32m   1335\u001b[0m     loaders\u001b[38;5;241m=\u001b[39mloaders,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1338\u001b[0m     targets\u001b[38;5;241m=\u001b[39mstrax\u001b[38;5;241m.\u001b[39mto_str_tuple(final_plugin),\n\u001b[1;32m   1339\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/DELight_mtr/helix_test/helix/plugins/event_rqs/fit_results.py:74\u001b[0m, in \u001b[0;36mFitResults.setup\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msetup\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;66;03m# TODO: for the real data we might have different templates for each channel.\u001b[39;00m\n\u001b[0;32m---> 74\u001b[0m     templates \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtemplates_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_pickle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muv_template \u001b[38;5;241m=\u001b[39m templates[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mqp_template \u001b[38;5;241m=\u001b[39m templates[\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/delight/lib/python3.11/site-packages/numpy/lib/npyio.py:405\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    403\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    404\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 405\u001b[0m     fid \u001b[38;5;241m=\u001b[39m stack\u001b[38;5;241m.\u001b[39menter_context(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos_fspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    406\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    408\u001b[0m \u001b[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'plugins/event_rqs/default_templates.npy'"
     ]
    }
   ],
   "source": [
    "# creating context, registering storage and plugins\n",
    "context = sx.Context(storage=[sx.DataDirectory(helix_data_dir, provide_run_metadata=True), ],\n",
    "                     register=[hx.ToyDataRawRecords,\n",
    "                               hx.QPTriggers, hx.UVTriggers,\n",
    "                               hx.Events, hx.NoiseEvents,\n",
    "                               hx.NoisePSDs, hx.FitResults])    # all the plugins required for getting fit_results\n",
    "\n",
    "# creating a dictionary of plugins' options that we want to modify. \n",
    "config = {'run_metadata_directory': helix_data_dir,      # for the hx.ToyDataRawRecords plugin\n",
    "          'noise_events_random_seed': 1}                 # for the hx.NoiseEvents plugin\n",
    "\n",
    "# passing the settings to the plugins. Strax finds which plugins take these options automatically\n",
    "context.set_config(config)\n",
    "\n",
    "# running the processing (or retrieving the data, if it was processed earlier)\n",
    "\n",
    "\n",
    "#psds = context.get_array(run_id, 'noise_psds')  # Helix needs to prebuild PSDs before calculating fit_results\n",
    "\n",
    "\n",
    "fit_results = context.get_array(run_id, 'fit_results')  # hx.FitResults plugin provides this data type\n",
    "\n",
    "# fit_results is a structured numpy array of events containing fields described in the FitResults documentation\n",
    "# one can work with it as a dictionary on numpy arrays, or as a numpy array of dictionaries. Works both ways. E.g.\n",
    "# fit_results['sum_uv_amplitude'][:100]  # amplitudes of UV signals in the sum of all channels in the first 100 events\n",
    "# fit_results[:100]['sum_uv_amplitude']  # same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e6292e8-404c-4185-a054-ee872bb17959",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'chunk' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mchunk\u001b[49m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(chunk\u001b[38;5;241m.\u001b[39mdata)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'chunk' is not defined"
     ]
    }
   ],
   "source": [
    "print(chunk.data.dtype)\n",
    "print(chunk.data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ff9f8f2-b522-4315-ab72-caf8156509d6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fit_results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# to show all the field names stored in the fit_results numpy structured array\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mfit_results\u001b[49m\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mnames\n",
      "\u001b[0;31mNameError\u001b[0m: name 'fit_results' is not defined"
     ]
    }
   ],
   "source": [
    "# to show all the field names stored in the fit_results numpy structured array\n",
    "fit_results.dtype.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c68e6cf-9f38-4790-9a95-14414b1b6834",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2d scatter plot of QP vs UV signal amplitudes\n",
    "plt.scatter(fit_results['triggered_uv_amplitude'], fit_results['triggered_qp_amplitude'])\n",
    "plt.xlabel('UV signal amplitude')\n",
    "plt.ylabel('QP signal amplitude')\n",
    "plt.xlim(-1000, 20000)\n",
    "plt.ylim(-1000, 40000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30ec9fb-12e6-49ae-bd6c-e1bd189ff5c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c092b16-f838-46af-bd37-e1eaa925720f",
   "metadata": {},
   "outputs": [],
   "source": [
    "events = context.get_array(run_id, 'events')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15dbc02d-299a-4a1d-b73a-f50ab66cfebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "events.dtype.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1c2060-c7da-4976-aff4-ee2e7898d5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the channel map and loading the templates\n",
    "\n",
    "channels = hx.Channels(hx.DEFAULT_CHANNEL_MAP)\n",
    "\n",
    "template_path = './plugins/event_rqs/default_templates.npy'\n",
    "templates = np.load(template_path, allow_pickle=True)\n",
    "uv_template = templates[0]\n",
    "qp_template = templates[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a31eb11-6027-4e0a-af28-ca3a4b4eb978",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change this to choose another event if the one below is a bad one by chance\n",
    "i = 3\n",
    "\n",
    "plt.figure(figsize=(10,16))\n",
    "artificial_baselines = np.arange(len(channels)) * 300  # adding artificial baselines to each channel to separate the channels on the plot\n",
    "plt.plot(events['channel_data'][i].T + artificial_baselines, lw=0.5, alpha=0.8, color='C0')  # plotting data in each channel\n",
    "\n",
    "event = fit_results[i]\n",
    "\n",
    "# plotting two-template fits in the vacuum channels\n",
    "for i_vac, i_ch in enumerate(channels.indices_of_type(hx.ChannelType.VACUUM)):\n",
    "    # i_vac is the ordinal index of the vacuum channel\n",
    "    # i_ch is the corrending ordinal index in the array of all channels\n",
    "    fit = event['vacuum_channel_uv_amplitude'][i_vac] * np.roll(uv_template, event['vacuum_channel_uv_offset'][i_vac]) + \\\n",
    "          event['vacuum_channel_qp_amplitude'][i_vac] * np.roll(qp_template, event['vacuum_channel_qp_offset'][i_vac])\n",
    "    x = np.arange(len(uv_template)) - hx.DEFAULT_ALLOWED_FIT_SHIFTS[0]  # currently, the FitResults plugin does not fit the entire event. It skips -hx.DEFAULT_ALLOWED_FIT_SHIFTS[0] samples.\n",
    "    plt.plot(x, fit+artificial_baselines[i_ch], lw=1, alpha=0.8, color='C1')\n",
    "\n",
    "# plotting one-template fits in the submerged channels\n",
    "for i_sub, i_ch in enumerate(channels.indices_of_type(hx.ChannelType.SUBMERGED)):\n",
    "    fit = event['submerged_channel_uv_amplitude'][i_sub] * np.roll(uv_template, event['submerged_channel_uv_offset'][i_sub])\n",
    "    x = np.arange(len(uv_template)) - hx.DEFAULT_ALLOWED_FIT_SHIFTS[0]\n",
    "    plt.plot(x, fit+artificial_baselines[i_ch], lw=1, color='C3')\n",
    "\n",
    "\n",
    "plt.xlabel('Time (samples)')\n",
    "plt.ylabel('Current (ADC units)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269a1a24-b306-4f8e-adc6-50c8b9bb4991",
   "metadata": {},
   "source": [
    "### Please, clear the output of all cells after running this notebook. Do not push the cell outputs to git!\n",
    "In the upper left corner click Edit -> Clear outputs of all cells"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
